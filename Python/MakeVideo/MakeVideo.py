r"""
===============================================================
 Script: MakeVideo.py
 Autor: Leandro
===============================================================
üìå O que este script faz?
---------------------------------------------------------------
Gera v√≠deos educativos (MP4) a partir de um arquivo JSON
com imagem de fundo, TTS (voz neural Google ou Gemini) e legendas.

Suporta 3 modos de voz:
1Ô∏è‚É£ gTTS (padr√£o simples)
2Ô∏è‚É£ Google Cloud TTS (Wavenet neural)
3Ô∏è‚É£ Gemini 2.5 Pro Preview TTS (AI Studio - ultra natural)

Novidades:
 - Escolha de modo de voz e fallback
 - Controle autom√°tico de pitch e velocidade por idioma
 - Fundo desfocado proporcional (sem distor√ß√£o)
 - Fundo transl√∫cido atr√°s do texto (parametriz√°vel)
 - Gera√ß√£o inteligente (v√≠deo completo ou se√ß√µes + completo)
 - Total compatibilidade com JSONs de treino multil√≠ngue
 - Caminho JSON configur√°vel por vari√°vel

Execu√ß√£o:
    python .\MakeVideo.py
===============================================================
"""

import os
import json
import shutil
import base64
import requests
from datetime import datetime
from gtts import gTTS
from PIL import Image, ImageFilter
from moviepy.editor import (
    AudioFileClip, TextClip, ImageClip, ColorClip,
    CompositeVideoClip, concatenate_videoclips
)
from moviepy.config import change_settings
from google.cloud import texttospeech

# --- Corrige compatibilidade Pillow 10+ ---
if not hasattr(Image, "ANTIALIAS"):
    Image.ANTIALIAS = Image.Resampling.LANCZOS

change_settings({"IMAGEMAGICK_BINARY": "magick"})

# ============================================================
# CONFIGURA√á√ïES GERAIS
# ============================================================
VIDEO_SIZE = (1280, 720)
TEXT_COLOR = "white"
FONT = "Arial-Bold"
BACKGROUND_IMAGE = "Teacher_Leandrinho.png"

TEMP_DIR = "./temp"
# OUTPUT_DIR = "./Videos/Gemini"
OUTPUT_DIR = "C:\\Users\\leand\\LTS - CONSULTORIA E DESENVOLVtIMENTO DE SISTEMAS\\LTS SP Site - Audios para estudar ingl√™s\\VideosGeradosPorScript\\GOOGLE_TTS\\WordBank"
TEXT_BG_COLOR = (0, 0, 0)
TEXT_BG_OPACITY = 0.55
BLUR_AMOUNT = 18
SUBTITLE_POSITION = "bottom"

# ============================================================
# CONFIGURA√á√ÉO DE VOZ
# ============================================================
VOICE_MODE = "GOOGLE_TTS"   # "GTTS", "GOOGLE_TTS" ou "GEMINI"
VOICE_TYPE = "male"
ENABLE_FALLBACK = False

GOOGLE_TTS_CREDENTIALS = os.path.join(os.path.dirname(__file__), "google-tts.json")
GEMINI_KEY_PATH = os.path.join(os.path.dirname(__file__), "google-gemini-key.txt")

# Caminho do arquivo JSON de entrada (parametriz√°vel) - o padr√£o √© textos.json
JSON_FILE_PATH = os.path.join(os.path.dirname(__file__), "textos.json")

# Mapeamento de vozes do Google Cloud
VOICE_MAP = {
    ("pt", "female"): "pt-BR-Wavenet-F",
    ("pt", "male"): "pt-BR-Wavenet-B",
    ("en", "female"): "en-US-Wavenet-F",
    ("en", "male"): "en-US-Wavenet-D",
    ("es", "female"): "es-ES-Wavenet-C",
    ("es", "male"): "es-ES-Wavenet-B",
    ("fr", "female"): "fr-FR-Wavenet-C",
    ("fr", "male"): "fr-FR-Wavenet-B",
}

default_voiceSpeed = {"pt": 3, "en": 1, "es": 2, "fr": 2}
default_repeat = {"pt": 1, "en": 2, "es": 1, "fr": 1}

# ============================================================
# FUN√á√ïES AUXILIARES
# ============================================================

def ensure_dirs():
    timestamp = datetime.now().strftime("%Y%m%d_%H%M")
    base_dir = os.path.join(TEMP_DIR, timestamp)
    os.makedirs(base_dir, exist_ok=True)
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    return base_dir


def generate_blurred_background(source_path, output_path):
    img = Image.open(source_path).convert("RGB")
    img_ratio = img.width / img.height
    video_ratio = VIDEO_SIZE[0] / VIDEO_SIZE[1]
    if img_ratio > video_ratio:
        new_height = VIDEO_SIZE[1]
        new_width = int(img_ratio * new_height)
    else:
        new_width = VIDEO_SIZE[0]
        new_height = int(new_width / img_ratio)
    img = img.resize((new_width, new_height), Image.LANCZOS)
    blurred = img.filter(ImageFilter.GaussianBlur(radius=BLUR_AMOUNT))
    left = (blurred.width - VIDEO_SIZE[0]) // 2
    top = (blurred.height - VIDEO_SIZE[1]) // 2
    cropped = blurred.crop((left, top, left + VIDEO_SIZE[0], top + VIDEO_SIZE[1]))
    cropped.save(output_path)
    return output_path


def cleanup_temp(base_dir):
    try:
        if os.path.exists(base_dir):
            shutil.rmtree(base_dir)
            print(f"üßπ Diret√≥rio tempor√°rio removido: {base_dir}")
    except Exception as e:
        print(f"‚ö†Ô∏è Erro ao remover tempor√°rios: {e}")

# ============================================================
# GERA√á√ÉO DE TTS
# ============================================================

def generate_tts_gemini(text, lang, filename):
    """Gera voz natural usando Gemini 2.5 Pro Preview TTS via REST API (formato 2025-11)"""
    try:
        if not os.path.exists(GEMINI_KEY_PATH):
            raise FileNotFoundError("Arquivo google-gemini-key.txt n√£o encontrado.")
        with open(GEMINI_KEY_PATH) as f:
            key = f.read().strip()

        url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro-preview-tts:generateContent?key={key}"

        # Sele√ß√£o de voz
        if lang == "pt":
            style = "Read aloud in Brazilian Portuguese with a lively, warm, and encouraging teacher tone."
            voice = "Charon"
        elif lang == "en":
            style = "Read aloud in English with a clear, calm, and friendly educational tone."
            voice = "Puck"
        else:
            style = f"Read aloud in {lang} with a natural and instructive tone."
            voice = "Fenrir"

        # ‚úÖ Estrutura correta atual (2025-11)
        payload = {
            "contents": [{"role": "user", "parts": [{"text": f"{style}\n\n{text}"}]}],
            "generationConfig": {
                "responseModalities": ["AUDIO"]
            },
            "audioConfig": {
                "voiceConfig": {"speaker": voice},
                "audioEncoding": "MP3"
            }
        }

        headers = {"Content-Type": "application/json"}
        response = requests.post(url, headers=headers, json=payload)
        if response.status_code != 200:
            raise RuntimeError(f"Erro Gemini: {response.status_code} {response.text}")

        data = response.json()
        audio_b64 = (
            data.get("candidates", [{}])[0]
            .get("content", {})
            .get("parts", [{}])[0]
            .get("inline_data", {})
            .get("data")
        )

        if not audio_b64:
            raise RuntimeError("A resposta do Gemini n√£o cont√©m dados de √°udio base64.")

        with open(filename, "wb") as f:
            f.write(base64.b64decode(audio_b64))

        return filename

    except Exception as ex:
        print(f"‚ö†Ô∏è Erro no Gemini TTS: {ex}")
        if ENABLE_FALLBACK:
            return generate_tts_google(text, lang, 1, filename, VOICE_TYPE)
        raise




def generate_tts_google(text, lang, velocidade, filename, voice="female"):
    try:
        client = texttospeech.TextToSpeechClient.from_service_account_file(GOOGLE_TTS_CREDENTIALS)
        lang_code = lang + "-BR" if lang == "pt" else lang
        name = VOICE_MAP.get((lang, voice), f"{lang_code}-Wavenet-A")

        if lang == "pt":
            pitch = 2.0 if voice == "female" else 0.5
            rate = 1.05
        elif lang == "en":
            pitch = -0.5
            rate = 0.82
        elif lang == "es":
            pitch = 0.5
            rate = 0.95
        else:
            pitch = 0.0
            rate = 0.9

        voice_params = texttospeech.VoiceSelectionParams(
            language_code=lang_code,
            name=name,
            ssml_gender=texttospeech.SsmlVoiceGender.MALE if voice == "male" else texttospeech.SsmlVoiceGender.FEMALE
        )
        audio_config = texttospeech.AudioConfig(
            audio_encoding=texttospeech.AudioEncoding.MP3,
            speaking_rate=rate,
            pitch=pitch
        )
        response = client.synthesize_speech(
            input=texttospeech.SynthesisInput(text=text),
            voice=voice_params,
            audio_config=audio_config
        )
        with open(filename, "wb") as out:
            out.write(response.audio_content)
        return filename
    except Exception as ex:
        print(f"‚ö†Ô∏è Erro no Google TTS: {ex}")
        if ENABLE_FALLBACK:
            return generate_tts_gtts(text, lang, filename)
        raise


def generate_tts_gtts(text, lang, filename):
    tts = gTTS(text=text, lang=lang, slow=False)
    tts.save(filename)
    return filename


def generate_tts(text, lang, velocidade, filename, voice_type):
    if VOICE_MODE == "GEMINI":
        return generate_tts_gemini(text, lang, filename)
    elif VOICE_MODE == "GOOGLE_TTS":
        return generate_tts_google(text, lang, velocidade, filename, voice_type)
    else:
        return generate_tts_gtts(text, lang, filename)

# ============================================================
# CRIA√á√ÉO DE CLIPES
# ============================================================

def create_text_clip(text, duration, blurred_image, sharp_image):
    if not text.strip():
        return ImageClip(sharp_image).set_duration(duration)
    bg_blurred = ImageClip(blurred_image).set_duration(duration)
    sharp_clip = ImageClip(sharp_image).resize(height=VIDEO_SIZE[1]).set_position("center").set_duration(duration)
    txt_clip = TextClip(
        text, fontsize=50, color=TEXT_COLOR, font=FONT,
        method="caption", align="center", size=(int(VIDEO_SIZE[0]*0.9), None)
    ).set_duration(duration)
    txt_bg = ColorClip(
        size=(int(VIDEO_SIZE[0]*0.9), txt_clip.h + 30),
        color=TEXT_BG_COLOR
    ).set_opacity(TEXT_BG_OPACITY).set_duration(duration)
    pos_y = VIDEO_SIZE[1] - txt_clip.h - 80 if SUBTITLE_POSITION == "bottom" else \
            50 if SUBTITLE_POSITION == "top" else (VIDEO_SIZE[1] - txt_clip.h) // 2
    return CompositeVideoClip([
        bg_blurred,
        sharp_clip,
        txt_bg.set_position(("center", pos_y)),
        txt_clip.set_position(("center", pos_y))
    ])


def create_video_segment(text, lang, velocidade, idx, base_dir, voice_type, blurred_image, sharp_image):
    temp_audio = os.path.join(base_dir, f"tmp_{idx}.mp3")
    generate_tts(text, lang, velocidade, temp_audio, voice_type)
    audio = AudioFileClip(temp_audio)
    txt_clip = create_text_clip(text, audio.duration, blurred_image, sharp_image)
    return txt_clip.set_audio(audio)


def process_block(items, base_dir, velocidades, repeat_each, voice_type, blurred_image, sharp_image):
    clips = []
    idx = 1
    for item in items:
        if isinstance(item, dict) and "text" in item and "lang" in item:
            lang = item["lang"]
            text = item["text"]
            velocidade = item.get("VoiceSpeed", velocidades.get(lang, 2))
            rep = item.get("repeat", repeat_each.get(lang, 1))
            for r in range(rep):
                clip = create_video_segment(text, lang, velocidade, f"{idx}_{r}", base_dir, voice_type, blurred_image, sharp_image)
                clips.append(clip)
            if "pause" in item:
                clips.append(ImageClip(blurred_image).set_duration(item["pause"] / 1000))
            idx += 1
    return clips

# ============================================================
# EXECU√á√ÉO PRINCIPAL
# ============================================================

def main():
    try:
        with open(JSON_FILE_PATH, "r", encoding="utf-8") as f:
            conteudo = json.load(f)
    except Exception as e:
        print(f"Erro ao ler JSON: {e}")
        return

    velocidades = default_voiceSpeed.copy()
    repeat_each = default_repeat.copy()
    if "velocidades" in conteudo:
        velocidades.update(conteudo["velocidades"])
    if "repeat_each" in conteudo:
        repeat_each.update(conteudo["repeat_each"])

    nome_arquivos = conteudo.get("nome_arquivos", "EstudoIdiomas")
    introducao = conteudo.get("introducao")

    secoes = [k for k in conteudo.keys() if k not in ("velocidades", "repeat_each", "introducao", "nome_arquivos")]
    base_dir = ensure_dirs()
    blurred_path = os.path.join(base_dir, "blurred_bg.jpg")
    generate_blurred_background(BACKGROUND_IMAGE, blurred_path)

    print(f"üé¨ Gerando v√≠deos educativos com VOICE_MODE = {VOICE_MODE}")

    all_clips = []

    if introducao:
        intro_clip = create_video_segment(introducao, "pt", velocidades.get("pt", 2), "intro", base_dir, VOICE_TYPE, blurred_path, BACKGROUND_IMAGE)
        all_clips.append(intro_clip)

    for section in secoes:
        print(f"üìñ Se√ß√£o: {section}")
        clips = process_block(conteudo[section], base_dir, velocidades, repeat_each, VOICE_TYPE, blurred_path, BACKGROUND_IMAGE)
        if clips:
            section_video = concatenate_videoclips(clips, method="compose")
            section_path = os.path.join(OUTPUT_DIR, f"{nome_arquivos}_{section}.mp4")
            section_video.write_videofile(section_path, fps=24, codec="libx264", audio_codec="aac")
            print(f"‚úÖ V√≠deo salvo: {section_path}")
            all_clips.extend(clips)

    if all_clips:
        final_video = concatenate_videoclips(all_clips, method="compose")
        final_path = os.path.join(OUTPUT_DIR, f"{nome_arquivos}_FULL.mp4")
        final_video.write_videofile(final_path, fps=24, codec="libx264", audio_codec="aac", preset="medium")
        print(f"üéâ V√≠deo completo gerado: {final_path}")

    cleanup_temp(base_dir)
    print("‚úÖ Processo conclu√≠do!")


if __name__ == "__main__":
    main()
